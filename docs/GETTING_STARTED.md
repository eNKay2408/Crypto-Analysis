# ğŸš€ Getting Started - Crypto Analysis System

Complete guide to run the full-stack crypto analysis application.

---

## ğŸ“‹ Prerequisites

### Required Software
```
âœ… Java 21 (JDK)
âœ… Maven 3.8+
âœ… Node.js 18+ & npm
âœ… Python 3.9+
âœ… Docker Desktop
âœ… Git
```

### API Keys (Optional but Recommended)
- **Google Gemini API Key** (FREE): https://ai.google.dev/
  - Used for AI Structure Learner and Causal Analysis
  - Free tier: 60 requests/minute

---

## âš¡ Quick Start (5 Minutes)

### Step 1: Clone Repository
```bash
git clone https://github.com/eNKay2408/Crypto-Analysis.git
cd Crypto-Analysis
```

### Step 2: Start Databases (Docker)
```bash
# Start all services (PostgreSQL, MongoDB, Redis, TimescaleDB)
docker-compose up -d

# Verify all containers are running
docker-compose ps
```

Expected output:
```
NAME                    STATUS
crypto-mongodb          Up
crypto-postgres         Up
crypto-redis            Up
crypto-timescaledb      Up
```

### Step 3: Start Backend
```bash
cd backend

# Copy .env and fill in missing values
cp .env.example .env

# Install dependencies & run
mvn clean install
mvn spring-boot:run
```

âœ… Backend running on: **http://localhost:8080**  
âœ… Swagger UI: **http://localhost:8080/swagger-ui.html**

### Step 4: Start Frontend
```bash
# Open new terminal
cd frontend

# Copy .env and fill in missing values
cp .env.example .env

# Install dependencies
npm install

# Start dev server
npm run dev
```

âœ… Frontend running on: **http://localhost:5173**

### Step 5: Start AI Engine (Optional)
```bash
# Open new terminal
cd ai_engine

# Install dependencies
pip install -r requirements.txt

# Copy .env and fill in missing values
cp ai_worker/.env.example ai_worker/.env
cp crawler/.env.example crawler/.env

# Start AI worker (processes new articles)
python -m ai_worker.messaging.ArticleChangeStreamConsumer

# In another terminal, start crawler (optional - fetches news every 60s)
python -m crawler.scheduler.CrawlScheduler
```

---

## ğŸ§ª Integration Testing

### 1. Test Authentication Flow
```bash
# Frontend: http://localhost:5173
1. Click "Register"
2. Fill form:
   - Name: Test User
   - Email: test@example.com
   - Password: Test123!
   - Confirm Password: Test123!
3. Click "Register" button
4. âœ… Should redirect to /dashboard
5. âœ… Header shows "Welcome, Test User"
6. Click "Logout"
7. âœ… Redirected to /login
8. Try access /dashboard directly
9. âœ… Redirected to /login (protected route)
```

### 2. Test Real-time Chart
```bash
# Dashboard page: http://localhost:5173/dashboard
1. âœ… Chart loads with BTC/USDT historical data (1000 candles)
2. âœ… Market stats show: Price, 24h Change %, High, Low, Volume
3. Wait 5-10 seconds
4. âœ… Price updates in real-time (via WebSocket)
5. âœ… Candle updates (isFinal: false â†’ updates, isFinal: true â†’ new candle)
6. Change interval (1m, 5m, 15m, 1h, 4h, 1d)
7. âœ… Chart reloads with new timeframe data
```

### 3. Test News Analysis
```bash
# News Analysis page: http://localhost:5173/news-analysis
1. âœ… See list of news articles
2. âœ… Sentiment Chart displays positive/negative/neutral distribution
3. Apply filters:
   - Date range: Last 7 days
   - Sentiment: Positive only
4. âœ… List updates with filtered results
5. âœ… Each article shows:
   - Title, source, date
   - Sentiment badge (ğŸ“ˆ/ğŸ“‰/ğŸ“Š)
   - Sentiment score
   - Keywords/entities
```

### 4. Test AI Causal Analysis (Requires Gemini API Key)
```bash
# News Analysis page
1. Find any news article card
2. Click "AI Analyze" button
3. âœ… Loading state shows "Analyzing..."
4. Wait 2-5 seconds
5. âœ… Modal opens with:
   - Predicted Trend: ğŸ“ˆ Up / ğŸ“‰ Down / ğŸ“Š Neutral
   - Confidence: X%
   - Analysis: Detailed explanation
   - Key Factors: Bullet points
   - Related Entities: Tags
6. Click X or outside modal to close
7. âœ… Modal closes
8. Click "AI Analyze" again on same article
9. âœ… Cached result loads instantly
```

### 5. Test AI Engine (Python)

#### Test Crawler
```bash
cd ai_engine
python -m crawler.worker.coindesk_btc_crawler

# Expected output:
# âœ… Fetching page list: https://www.coindesk.com/tag/bitcoin/1
# âœ… Successfully crawled X URLs
# âœ… Crawling detail: https://...
# âœ… Saved to MongoDB
```

#### Test AI Structure Learner
```bash
cd ai_engine
python -m crawler.worker.ai_structure_learner

# Expected output:
# ğŸ¤– AI Structure Learner: coindesk
# ğŸ“¥ Fetching HTML from https://...
# ğŸ¤– Calling Gemini AI...
# âœ… Successfully learned structure
# âœ… Template validation passed
```

#### Test Sentiment Analysis
```bash
cd ai_engine
python -m ai_worker.sentiment_analysis.SentimentAnalysisWorker

# Expected output:
# Scenario: TIN Tá»T (Bullish)
# Result  : Label = POSITIVE | Numeric Score = 0.92
```

---

## ğŸ“Š Verify Database

### Check PostgreSQL

1. Go to `http://localhost:8082/` (pgAdmin)
2. Login with:
   - System: PostgresSQL
   - Server: crypto_postgres
   - Username: admin
   - Password: admin123
   - Database: crypto_auth
3. Navigate to `Schemas > public > Tables`

### Check MongoDB

1. Go to `http://localhost:8081/` (Mongo Express)
2. Login with (if prompted):
   - Username: admin
   - Password: admin123
3. Select database: `crypto_news`

### Check Redis

Option 1: Use Redis CLI:
```bash
docker exec -it crypto-redis redis-cli

# Check cached candles
KEYS candles:*

# Check TTL
TTL candles:BTCUSDT:1h

# Exit
exit
```
Option 2: Use RedisInsight (GUI):
1. Download and install RedisInsight: https://redis.com/redis-enterprise/redis-insight/
2. Connect to Redis at `localhost:6379`
3. Browse keys and inspect cached data

---

## ğŸ¯ Feature Verification Checklist

### Core Features (8/10 points)
- [ ] âœ… User Registration & Login (JWT authentication)
- [ ] âœ… TradingView chart displays BTC/USDT data
- [ ] âœ… Real-time price updates via WebSocket
- [ ] âœ… News crawler runs and saves articles to MongoDB
- [ ] âœ… News list displays with sentiment analysis
- [ ] âœ… AI sentiment analysis (FinBERT) processes articles

### Advanced Features (2+ points)
- [ ] âœ… AI Structure Learner (Gemini API) learns HTML selectors
- [ ] âœ… Causal Analysis predicts market impact with reasoning
- [ ] âœ… Redis caching for performance
- [ ] âœ… Docker Compose for easy deployment

### System Requirements
- [ ] âœ… Multiple news sources (CoinDesk, VietStock)
- [ ] âœ… Historical data (1000 candles from Binance)
- [ ] âœ… Real-time updates (WebSocket integration)
- [ ] âœ… Scalable architecture (Docker, Redis, Load distribution ready)

---

## ğŸ“ Project Structure

```
CryptoAnalysis/
â”œâ”€â”€ backend/                 # Spring Boot REST API
â”‚   â”œâ”€â”€ src/main/java/
â”‚   â”‚   â””â”€â”€ com/cryptoanalysis/
â”‚   â”‚       â”œâ”€â”€ auth/       # JWT authentication
â”‚   â”‚       â”œâ”€â”€ news/       # News API
â”‚   â”‚       â”œâ”€â”€ candle/     # Candles API (Binance proxy)
â”‚   â”‚       â”œâ”€â”€ analysis/   # Causal Analysis API
â”‚   â”‚       â””â”€â”€ websocket/  # WebSocket relay service
â”‚   â””â”€â”€ pom.xml
â”‚
â”œâ”€â”€ frontend/               # React + TypeScript
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pages/         # Login, Register, Dashboard, NewsAnalysis
â”‚   â”‚   â”œâ”€â”€ components/    # Chart, News list, Sentiment chart
â”‚   â”‚   â”œâ”€â”€ services/      # API client, WebSocket client
â”‚   â”‚   â””â”€â”€ contexts/      # Auth context
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ ai_engine/              # Python AI pipeline
â”‚   â”œâ”€â”€ crawler/           # News crawler with scheduler
â”‚   â”œâ”€â”€ ai_worker/         # Sentiment analysis, NER
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ docker-compose.yml      # All databases
â””â”€â”€ docs/                   # Documentation
    â”œâ”€â”€ phase/             # Phase 1-3 implementation reports
    â””â”€â”€ REQUIREMENTS.md    # Original project requirements
```

---

## ğŸš€ Production Deployment

### Build for Production

#### Backend
```bash
cd backend
mvn clean package -DskipTests

# JAR file: target/crypto-analysis-0.0.1-SNAPSHOT.jar
java -jar target/crypto-analysis-0.0.1-SNAPSHOT.jar
```

#### Frontend
```bash
cd frontend
npm run build

# Static files: dist/
# Deploy to: Nginx, Vercel, Netlify, etc.
```

### Environment Variables for Production
```bash
# Backend
POSTGRES_HOST=production-postgres-host
POSTGRES_PORT=5432
MONGODB_HOST=production-mongo-host
REDIS_HOST=production-redis-host
JWT_SECRET=your-super-secret-key-change-this
GEMINI_API_KEY=your-production-api-key

# Frontend
VITE_API_BASE_URL=https://api.yourapp.com
VITE_WS_URL=https://api.yourapp.com/ws
```

---

## ğŸ“š Additional Resources

- **API Documentation**: http://localhost:8080/swagger-ui.html
- **Phase 1 Report**: [docs/phase/PHASE1_README.md](docs/phase/PHASE1_README.md)
- **Phase 2 Report**: [docs/phase/PHASE2_README.md](docs/phase/PHASE2_README.md)
- **Phase 3 Report**: [docs/phase/PHASE3_README.md](docs/phase/PHASE3_README.md)
- **Requirements**: [docs/REQUIREMENTS.md](docs/REQUIREMENTS.md)
- **Architecture**: [docs/technical/ARCHITECTURE.md](docs/technical/ARCHITECTURE.md)